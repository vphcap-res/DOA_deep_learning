{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz+dfYmP6bOBWUFevGWxti",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vphcap-res/DOA_deep_learning/blob/main/LowDOA_DL_20250211.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set random seed\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Ensure full determinism in TensorFlow operations\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "\n",
        "print(\"✅ Random seed set. Training will be reproducible.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9kQKs4VJo0W",
        "outputId": "791a8224-7fdc-461b-8205-3b856c215671"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Random seed set. Training will be reproducible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data  Loading and Preprocessing**"
      ],
      "metadata": {
        "id": "NsSzAH1V30pc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "L_aBElROzXIo",
        "outputId": "2f15e8ca-c434-4be6-87d7-5c89df5fbe56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        date  order        farm  distance  head  age    bw  \\\n",
              "0 2022-01-04      1  Pravatfarm     130.0  1200   43  3.18   \n",
              "1 2022-01-04      2  Pravatfarm     130.0  1200   43  3.12   \n",
              "2 2022-01-04      4  Pravatfarm     130.0  1100   43  3.20   \n",
              "3 2022-01-04      5  Pravatfarm     130.0  1028   43  3.04   \n",
              "4 2022-01-04      6    Natfarm2      55.0  1300   43  3.37   \n",
              "\n",
              "          timeoutfarm          timearrive       slaughtertime  lairagetemp  \\\n",
              "0 1900-01-01 01:00:00 1900-01-01 03:00:00 1900-01-01 05:30:00         24.0   \n",
              "1 1900-01-01 01:50:00 1900-01-01 04:10:00 1900-01-01 06:05:00         24.0   \n",
              "2 1900-01-01 03:30:00 1900-01-01 06:14:00 1900-01-01 07:14:00         25.4   \n",
              "3 1900-01-01 04:20:00 1900-01-01 06:27:00 1900-01-01 07:47:00         25.6   \n",
              "4 1900-01-01 05:45:00 1900-01-01 07:19:00 1900-01-01 08:27:00         24.2   \n",
              "\n",
              "   doa    pctdoa  orderc  season timetransport  durationtransport  lairagetime  \n",
              "0    0  0.000000   Early  Winter         Night                120          150  \n",
              "1    0  0.000000   Early  Winter         Night                140          115  \n",
              "2    1  0.090909   Early  Winter         Night                164           60  \n",
              "3    1  0.097276   Early  Winter       Morning                127           80  \n",
              "4    0  0.000000  Middle  Winter       Morning                 94           68  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6e1d28f-4f5f-4596-ac3f-75cfe2b94843\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>order</th>\n",
              "      <th>farm</th>\n",
              "      <th>distance</th>\n",
              "      <th>head</th>\n",
              "      <th>age</th>\n",
              "      <th>bw</th>\n",
              "      <th>timeoutfarm</th>\n",
              "      <th>timearrive</th>\n",
              "      <th>slaughtertime</th>\n",
              "      <th>lairagetemp</th>\n",
              "      <th>doa</th>\n",
              "      <th>pctdoa</th>\n",
              "      <th>orderc</th>\n",
              "      <th>season</th>\n",
              "      <th>timetransport</th>\n",
              "      <th>durationtransport</th>\n",
              "      <th>lairagetime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>1</td>\n",
              "      <td>Pravatfarm</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1200</td>\n",
              "      <td>43</td>\n",
              "      <td>3.18</td>\n",
              "      <td>1900-01-01 01:00:00</td>\n",
              "      <td>1900-01-01 03:00:00</td>\n",
              "      <td>1900-01-01 05:30:00</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Early</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Night</td>\n",
              "      <td>120</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>2</td>\n",
              "      <td>Pravatfarm</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1200</td>\n",
              "      <td>43</td>\n",
              "      <td>3.12</td>\n",
              "      <td>1900-01-01 01:50:00</td>\n",
              "      <td>1900-01-01 04:10:00</td>\n",
              "      <td>1900-01-01 06:05:00</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Early</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Night</td>\n",
              "      <td>140</td>\n",
              "      <td>115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>4</td>\n",
              "      <td>Pravatfarm</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1100</td>\n",
              "      <td>43</td>\n",
              "      <td>3.20</td>\n",
              "      <td>1900-01-01 03:30:00</td>\n",
              "      <td>1900-01-01 06:14:00</td>\n",
              "      <td>1900-01-01 07:14:00</td>\n",
              "      <td>25.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>Early</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Night</td>\n",
              "      <td>164</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>5</td>\n",
              "      <td>Pravatfarm</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1028</td>\n",
              "      <td>43</td>\n",
              "      <td>3.04</td>\n",
              "      <td>1900-01-01 04:20:00</td>\n",
              "      <td>1900-01-01 06:27:00</td>\n",
              "      <td>1900-01-01 07:47:00</td>\n",
              "      <td>25.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.097276</td>\n",
              "      <td>Early</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Morning</td>\n",
              "      <td>127</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>6</td>\n",
              "      <td>Natfarm2</td>\n",
              "      <td>55.0</td>\n",
              "      <td>1300</td>\n",
              "      <td>43</td>\n",
              "      <td>3.37</td>\n",
              "      <td>1900-01-01 05:45:00</td>\n",
              "      <td>1900-01-01 07:19:00</td>\n",
              "      <td>1900-01-01 08:27:00</td>\n",
              "      <td>24.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Middle</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Morning</td>\n",
              "      <td>94</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6e1d28f-4f5f-4596-ac3f-75cfe2b94843')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6e1d28f-4f5f-4596-ac3f-75cfe2b94843 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6e1d28f-4f5f-4596-ac3f-75cfe2b94843');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0fe8dda6-1fbf-40ac-83de-9268f24da416\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fe8dda6-1fbf-40ac-83de-9268f24da416')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0fe8dda6-1fbf-40ac-83de-9268f24da416 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# n = 8220\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-01-04 00:00:00\",\n        \"max\": \"2022-01-04 00:00:00\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2022-01-04 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"farm\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Natfarm2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.54101966249684,\n        \"min\": 55.0,\n        \"max\": 130.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          55.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"head\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104,\n        \"min\": 1028,\n        \"max\": 1300,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 43,\n        \"max\": 43,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bw\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12214745187681979,\n        \"min\": 3.04,\n        \"max\": 3.37,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timeoutfarm\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1900-01-01 01:00:00\",\n        \"max\": \"1900-01-01 05:45:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1900-01-01 01:50:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timearrive\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1900-01-01 03:00:00\",\n        \"max\": \"1900-01-01 07:19:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1900-01-01 04:10:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slaughtertime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1900-01-01 05:30:00\",\n        \"max\": \"1900-01-01 08:27:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1900-01-01 06:05:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lairagetemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7924645102463582,\n        \"min\": 24.0,\n        \"max\": 25.6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          25.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pctdoa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05158582377409738,\n        \"min\": 0.0,\n        \"max\": 0.09727626459143969,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"orderc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Middle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Winter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timetransport\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Morning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"durationtransport\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 94,\n        \"max\": 164,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          140\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lairagetime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37,\n        \"min\": 60,\n        \"max\": 150,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Read the file (update path accordingly)\n",
        "file_path = \"/content/drive/My Drive/DOA-MeatDucks-SHAP/DOA-data_65-66_final_filtered.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Display first few rows\n",
        "df.head()\n",
        "\n",
        "# n = 8220"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove 'distance' and create lowDOA/highDOA classes based on the 75th percentile\n",
        "cutoff = df['pctdoa'].quantile(0.75)  # Calculate the 75th percentile cutoff\n",
        "\n",
        "# Drop the 'distance' column\n",
        "df2 = df.drop(columns=['distance']).copy()  # Copy ensures modifications do not affect df\n",
        "\n",
        "# Assign DOA classes\n",
        "df2['doaclass'] = df2['pctdoa'].apply(lambda x: 'lowDOA' if x < cutoff else 'highDOA')  # Fix: Use \"<\" instead of \"<=\"\n",
        "\n",
        "# Display the cutoff value and class distribution\n",
        "print(f\"✅ 75th Percentile Cutoff for pctdoa: {cutoff:.6f}\")\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(df2['doaclass'].value_counts(normalize=True) * 100)  # Corrected to df2\n",
        "\n",
        "# Show first few rows\n",
        "df2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "cu8Z66tB3zds",
        "outputId": "04e92bae-6176-4065-fa57-df2ba43b63ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 75th Percentile Cutoff for pctdoa: 0.153846\n",
            "\n",
            "Class Distribution:\n",
            "doaclass\n",
            "lowDOA     73.783455\n",
            "highDOA    26.216545\n",
            "Name: proportion, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        date  order        farm  head  age    bw         timeoutfarm  \\\n",
              "0 2022-01-04      1  Pravatfarm  1200   43  3.18 1900-01-01 01:00:00   \n",
              "1 2022-01-04      2  Pravatfarm  1200   43  3.12 1900-01-01 01:50:00   \n",
              "2 2022-01-04      4  Pravatfarm  1100   43  3.20 1900-01-01 03:30:00   \n",
              "3 2022-01-04      5  Pravatfarm  1028   43  3.04 1900-01-01 04:20:00   \n",
              "4 2022-01-04      6    Natfarm2  1300   43  3.37 1900-01-01 05:45:00   \n",
              "\n",
              "           timearrive       slaughtertime  lairagetemp  doa    pctdoa  orderc  \\\n",
              "0 1900-01-01 03:00:00 1900-01-01 05:30:00         24.0    0  0.000000   Early   \n",
              "1 1900-01-01 04:10:00 1900-01-01 06:05:00         24.0    0  0.000000   Early   \n",
              "2 1900-01-01 06:14:00 1900-01-01 07:14:00         25.4    1  0.090909   Early   \n",
              "3 1900-01-01 06:27:00 1900-01-01 07:47:00         25.6    1  0.097276   Early   \n",
              "4 1900-01-01 07:19:00 1900-01-01 08:27:00         24.2    0  0.000000  Middle   \n",
              "\n",
              "   season timetransport  durationtransport  lairagetime doaclass  \n",
              "0  Winter         Night                120          150   lowDOA  \n",
              "1  Winter         Night                140          115   lowDOA  \n",
              "2  Winter         Night                164           60   lowDOA  \n",
              "3  Winter       Morning                127           80   lowDOA  \n",
              "4  Winter       Morning                 94           68   lowDOA  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df2a2982-8897-4c9c-a20d-9d8cb75ff18c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>order</th>\n",
              "      <th>farm</th>\n",
              "      <th>head</th>\n",
              "      <th>age</th>\n",
              "      <th>bw</th>\n",
              "      <th>timeoutfarm</th>\n",
              "      <th>timearrive</th>\n",
              "      <th>slaughtertime</th>\n",
              "      <th>lairagetemp</th>\n",
              "      <th>doa</th>\n",
              "      <th>pctdoa</th>\n",
              "      <th>orderc</th>\n",
              "      <th>season</th>\n",
              "      <th>timetransport</th>\n",
              "      <th>durationtransport</th>\n",
              "      <th>lairagetime</th>\n",
              "      <th>doaclass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>1</td>\n",
              "      <td>Pravatfarm</td>\n",
              "      <td>1200</td>\n",
              "      <td>43</td>\n",
              "      <td>3.18</td>\n",
              "      <td>1900-01-01 01:00:00</td>\n",
              "      <td>1900-01-01 03:00:00</td>\n",
              "      <td>1900-01-01 05:30:00</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Early</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Night</td>\n",
              "      <td>120</td>\n",
              "      <td>150</td>\n",
              "      <td>lowDOA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>2</td>\n",
              "      <td>Pravatfarm</td>\n",
              "      <td>1200</td>\n",
              "      <td>43</td>\n",
              "      <td>3.12</td>\n",
              "      <td>1900-01-01 01:50:00</td>\n",
              "      <td>1900-01-01 04:10:00</td>\n",
              "      <td>1900-01-01 06:05:00</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Early</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Night</td>\n",
              "      <td>140</td>\n",
              "      <td>115</td>\n",
              "      <td>lowDOA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>4</td>\n",
              "      <td>Pravatfarm</td>\n",
              "      <td>1100</td>\n",
              "      <td>43</td>\n",
              "      <td>3.20</td>\n",
              "      <td>1900-01-01 03:30:00</td>\n",
              "      <td>1900-01-01 06:14:00</td>\n",
              "      <td>1900-01-01 07:14:00</td>\n",
              "      <td>25.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>Early</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Night</td>\n",
              "      <td>164</td>\n",
              "      <td>60</td>\n",
              "      <td>lowDOA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>5</td>\n",
              "      <td>Pravatfarm</td>\n",
              "      <td>1028</td>\n",
              "      <td>43</td>\n",
              "      <td>3.04</td>\n",
              "      <td>1900-01-01 04:20:00</td>\n",
              "      <td>1900-01-01 06:27:00</td>\n",
              "      <td>1900-01-01 07:47:00</td>\n",
              "      <td>25.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.097276</td>\n",
              "      <td>Early</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Morning</td>\n",
              "      <td>127</td>\n",
              "      <td>80</td>\n",
              "      <td>lowDOA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>6</td>\n",
              "      <td>Natfarm2</td>\n",
              "      <td>1300</td>\n",
              "      <td>43</td>\n",
              "      <td>3.37</td>\n",
              "      <td>1900-01-01 05:45:00</td>\n",
              "      <td>1900-01-01 07:19:00</td>\n",
              "      <td>1900-01-01 08:27:00</td>\n",
              "      <td>24.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Middle</td>\n",
              "      <td>Winter</td>\n",
              "      <td>Morning</td>\n",
              "      <td>94</td>\n",
              "      <td>68</td>\n",
              "      <td>lowDOA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df2a2982-8897-4c9c-a20d-9d8cb75ff18c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df2a2982-8897-4c9c-a20d-9d8cb75ff18c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df2a2982-8897-4c9c-a20d-9d8cb75ff18c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-446a8881-ab34-4186-8c40-b7de357a8a44\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-446a8881-ab34-4186-8c40-b7de357a8a44')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-446a8881-ab34-4186-8c40-b7de357a8a44 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2",
              "summary": "{\n  \"name\": \"df2\",\n  \"rows\": 8220,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-01-04 00:00:00\",\n        \"max\": \"2023-12-29 00:00:00\",\n        \"num_unique_values\": 592,\n        \"samples\": [\n          \"2023-09-09 00:00:00\",\n          \"2023-12-25 00:00:00\",\n          \"2022-08-30 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 20,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1,\n          18,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"farm\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 51,\n        \"samples\": [\n          \"Nongtarodfarm1\",\n          \"Nongwafarm\",\n          \"Chaisophonfarm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"head\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 129,\n        \"min\": 314,\n        \"max\": 1623,\n        \"num_unique_values\": 483,\n        \"samples\": [\n          796,\n          894,\n          1140\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 30,\n        \"max\": 47,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          43,\n          44,\n          46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bw\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3092945269830752,\n        \"min\": 2.0,\n        \"max\": 3.97,\n        \"num_unique_values\": 1753,\n        \"samples\": [\n          2.328,\n          2.911305147058823,\n          2.868421052631579\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timeoutfarm\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1900-01-01 00:00:00\",\n        \"max\": \"1900-01-01 23:55:00\",\n        \"num_unique_values\": 397,\n        \"samples\": [\n          \"1900-01-01 13:26:00\",\n          \"1900-01-01 16:00:00\",\n          \"1900-01-01 09:41:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timearrive\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1900-01-01 00:02:00\",\n        \"max\": \"1900-01-01 17:31:00\",\n        \"num_unique_values\": 755,\n        \"samples\": [\n          \"1900-01-01 07:59:00\",\n          \"1900-01-01 15:03:00\",\n          \"1900-01-01 07:37:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slaughtertime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1900-01-01 05:22:00\",\n        \"max\": \"1900-01-01 20:40:00\",\n        \"num_unique_values\": 759,\n        \"samples\": [\n          \"1900-01-01 10:09:00\",\n          \"1900-01-01 06:37:00\",\n          \"1900-01-01 14:34:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lairagetemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.903593840475952,\n        \"min\": 16.9,\n        \"max\": 38.1,\n        \"num_unique_values\": 168,\n        \"samples\": [\n          16.9,\n          25.8,\n          35.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 49,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          16,\n          37,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pctdoa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3211562859449723,\n        \"min\": 0.0,\n        \"max\": 6.499261447562777,\n        \"num_unique_values\": 835,\n        \"samples\": [\n          0.6382978723404255,\n          0.5309734513274336,\n          0.2339181286549708\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"orderc\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Early\",\n          \"Middle\",\n          \"Late\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Winter\",\n          \"Summer\",\n          \"Rainy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timetransport\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Night\",\n          \"Morning\",\n          \"Day\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"durationtransport\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 75,\n        \"min\": 5,\n        \"max\": 434,\n        \"num_unique_values\": 326,\n        \"samples\": [\n          178,\n          53,\n          314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lairagetime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39,\n        \"min\": 4,\n        \"max\": 374,\n        \"num_unique_values\": 252,\n        \"samples\": [\n          41,\n          109,\n          55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doaclass\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"highDOA\",\n          \"lowDOA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = (df2['doaclass'] == 'lowDOA').astype(int)  # lowDOA = 1, highDOA = 0\n",
        "print(\"✅ Unique Values in y:\", np.unique(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DunhEF7rqt43",
        "outputId": "7b7e63e0-a00d-4902-ebda-055e82eb00b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Unique Values in y: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"✅ Mapping of Target Classes:\")\n",
        "print(df2[['doaclass']].drop_duplicates().assign(encoded=y.unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSK3wu5mrFrH",
        "outputId": "41393ad8-cd5e-4a40-ee2a-735c9b546746"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Mapping of Target Classes:\n",
            "  doaclass  encoded\n",
            "0   lowDOA        1\n",
            "5  highDOA        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n🔍 Checking Label Assignment:\")\n",
        "print(f\"lowDOA is mapped to: {y[df2['doaclass'] == 'lowDOA'].unique()}\")\n",
        "print(f\"highDOA is mapped to: {y[df2['doaclass'] == 'highDOA'].unique()}\")"
      ],
      "metadata": {
        "id": "r9WXTWRkrMT3",
        "outputId": "49d1068a-a1de-4b26-983c-2bcc51fc797b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Checking Label Assignment:\n",
            "lowDOA is mapped to: [1]\n",
            "highDOA is mapped to: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create df3 as a copy of df2 to avoid modifying the original dataset\n",
        "df3 = df2.copy()\n",
        "\n",
        "# List of columns to remove\n",
        "columns_to_remove = [\n",
        "    'date', 'order', 'farm', 'timeoutfarm', 'timearrive', 'slaughtertime',\n",
        "    'doa', 'pctdoa'\n",
        "]\n",
        "\n",
        "# Drop the specified columns\n",
        "df3.drop(columns=columns_to_remove, inplace=True, errors='ignore')\n",
        "\n",
        "# Display the first few rows to confirm changes\n",
        "print(\"✅ Columns removed successfully. Preview of df3:\\n\")\n",
        "print(df3.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZEWTtLv_7vP",
        "outputId": "268759fc-157a-4c38-a566-ecce6c8ddda3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Columns removed successfully. Preview of df3:\n",
            "\n",
            "   head  age    bw  lairagetemp  orderc  season timetransport  \\\n",
            "0  1200   43  3.18         24.0   Early  Winter         Night   \n",
            "1  1200   43  3.12         24.0   Early  Winter         Night   \n",
            "2  1100   43  3.20         25.4   Early  Winter         Night   \n",
            "3  1028   43  3.04         25.6   Early  Winter       Morning   \n",
            "4  1300   43  3.37         24.2  Middle  Winter       Morning   \n",
            "\n",
            "   durationtransport  lairagetime doaclass  \n",
            "0                120          150   lowDOA  \n",
            "1                140          115   lowDOA  \n",
            "2                164           60   lowDOA  \n",
            "3                127           80   lowDOA  \n",
            "4                 94           68   lowDOA  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Splitting**"
      ],
      "metadata": {
        "id": "GvXoyyKxAn7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df3.drop(columns=['doaclass'])  # Features\n",
        "y = df3['doaclass']  # Target variable\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert categorical variables to numeric using one-hot encoding\n",
        "X = pd.get_dummies(df3.drop(columns=['doaclass']), drop_first=True)\n",
        "y = (df3['doaclass'] == 'lowDOA').astype(int)  # Convert target to binary\n",
        "\n",
        "# Convert categorical variables to numeric using one-hot encoding\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Ensure a balanced split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(\"✅ New Train-Test Split Completed.\")\n",
        "print(\"Unique values in y_train:\", np.unique(y_train))\n",
        "print(\"Unique values in y_test:\", np.unique(y_test))  # Should now show [0, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB5x_nUNAqGy",
        "outputId": "a0ba51ad-18ed-41f9-a6a5-1b642adced83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ New Train-Test Split Completed.\n",
            "Unique values in y_train: [0 1]\n",
            "Unique values in y_test: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check Class Imbalance**"
      ],
      "metadata": {
        "id": "MYRtfhysCvy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count occurrences of each class\n",
        "class_counts = df3['doaclass'].value_counts()\n",
        "\n",
        "# Print proportion\n",
        "print(\"✅ Class Distribution in Dataset:\")\n",
        "print(class_counts)\n",
        "print(\"\\nProportion (%):\")\n",
        "print(class_counts / class_counts.sum() * 100)\n",
        "\n",
        "# Plot bar chart for visualization\n",
        "plt.figure(figsize=(6, 4))\n",
        "class_counts.plot(kind='bar', color=['blue', 'red'])\n",
        "plt.xlabel(\"DOA Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of low DOA and high DOA\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "-aUNUXsfBbr2",
        "outputId": "d2c849d2-56ab-4bfc-e350-beaee06fd688"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Class Distribution in Dataset:\n",
            "doaclass\n",
            "lowDOA     6065\n",
            "highDOA    2155\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Proportion (%):\n",
            "doaclass\n",
            "lowDOA     73.783455\n",
            "highDOA    26.216545\n",
            "Name: count, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Resampling**"
      ],
      "metadata": {
        "id": "ziZM7C_8SCvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install imbalanced-learn if not installed\n",
        "!pip install imbalanced-learn  # Run this once in Colab/Jupyter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.combine import SMOTEENN  # ✅ Corrected Import\n",
        "import numpy as np\n",
        "\n",
        "# Apply Both Upsampling (lowDOA) & Undersampling (highDOA)\n",
        "smote_enn = SMOTEENN(random_state=42)  # Adjust parameters if needed\n",
        "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"✅ Resampling Completed (Upsampling lowDOA + Undersampling highDOA).\")\n",
        "print(\"Class Distribution in Resampled y_train:\", np.unique(y_train_resampled, return_counts=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdfU8G5ySGD2",
        "outputId": "82b36759-d99f-4e19-f4c4-098a2004b9ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "✅ Resampling Completed (Upsampling lowDOA + Undersampling highDOA).\n",
            "Class Distribution in Resampled y_train: (array([0, 1]), array([3016, 2167]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**"
      ],
      "metadata": {
        "id": "RtCmc4gfEyu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Feature Scaling (After Resampling)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
        "X_test_scaled = scaler.transform(X_test)  # Test set is NOT resampled, just scaled\n",
        "\n",
        "print(\"✅ Feature Scaling Applied.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rREfw-F8CsVG",
        "outputId": "82138af9-8cc8-4182-d8d7-487deebe105b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Feature Scaling Applied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build and Train the Deep Learning Model**"
      ],
      "metadata": {
        "id": "r2r7UWoIE-XY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1️⃣ Base MLP Model (Simple Architecture)**"
      ],
      "metadata": {
        "id": "GXHmYbNAF6SR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all boolean columns to int (0 or 1)\n",
        "X_train = X_train.astype(int)\n",
        "X_test = X_test.astype(int)\n",
        "\n",
        "print(\"✅ Boolean columns successfully converted to integers.\")\n",
        "print(X_train.dtypes)  # Verify all columns are now int64 or float64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NdWMz5vGGKh",
        "outputId": "8daf443d-b765-4739-9d36-ac12115012e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Boolean columns successfully converted to integers.\n",
            "head                     int64\n",
            "age                      int64\n",
            "bw                       int64\n",
            "lairagetemp              int64\n",
            "durationtransport        int64\n",
            "lairagetime              int64\n",
            "orderc_Late              int64\n",
            "orderc_Middle            int64\n",
            "season_Summer            int64\n",
            "season_Winter            int64\n",
            "timetransport_Morning    int64\n",
            "timetransport_Night      int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**"
      ],
      "metadata": {
        "id": "kENBmrwAGkyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"✅ Feature scaling applied successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jfRca-jGlYm",
        "outputId": "62f793c7-21c7-4768-c626-1b5b77ec3200"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Feature scaling applied successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ],
      "metadata": {
        "id": "Z0R3TTddGtsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.astype(float))  # Ensure float conversion\n",
        "X_test_scaled = scaler.transform(X_test.astype(float))\n",
        "\n",
        "print(\"✅ Feature Scaling Completed. All Data is Numeric.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGW8ZogEHT9s",
        "outputId": "ede99c17-d2e6-4db0-ae39-cb99100f212b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Feature Scaling Completed. All Data is Numeric.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "\n",
        "# Define the model\n",
        "model_base = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),  # Correct input layer\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_base.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_base = model_base.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=1)\n",
        "\n",
        "print(\"✅ Model Successfully Trained.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dGC9KH1Hcis",
        "outputId": "f3de60cb-07a0-4c4a-c760-fa8a07326c93"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7106 - loss: 0.5778 - val_accuracy: 0.7488 - val_loss: 0.5283\n",
            "Epoch 2/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7551 - loss: 0.5205 - val_accuracy: 0.7494 - val_loss: 0.5263\n",
            "Epoch 3/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7597 - loss: 0.5159 - val_accuracy: 0.7536 - val_loss: 0.5255\n",
            "Epoch 4/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7620 - loss: 0.5132 - val_accuracy: 0.7591 - val_loss: 0.5247\n",
            "Epoch 5/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7620 - loss: 0.5113 - val_accuracy: 0.7573 - val_loss: 0.5243\n",
            "Epoch 6/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7638 - loss: 0.5098 - val_accuracy: 0.7616 - val_loss: 0.5238\n",
            "Epoch 7/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7659 - loss: 0.5085 - val_accuracy: 0.7628 - val_loss: 0.5234\n",
            "Epoch 8/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7672 - loss: 0.5074 - val_accuracy: 0.7628 - val_loss: 0.5231\n",
            "Epoch 9/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7679 - loss: 0.5065 - val_accuracy: 0.7622 - val_loss: 0.5228\n",
            "Epoch 10/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7693 - loss: 0.5056 - val_accuracy: 0.7622 - val_loss: 0.5225\n",
            "Epoch 11/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7692 - loss: 0.5048 - val_accuracy: 0.7628 - val_loss: 0.5223\n",
            "Epoch 12/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7689 - loss: 0.5042 - val_accuracy: 0.7616 - val_loss: 0.5220\n",
            "Epoch 13/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7689 - loss: 0.5035 - val_accuracy: 0.7616 - val_loss: 0.5217\n",
            "Epoch 14/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7689 - loss: 0.5029 - val_accuracy: 0.7616 - val_loss: 0.5214\n",
            "Epoch 15/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7684 - loss: 0.5023 - val_accuracy: 0.7622 - val_loss: 0.5211\n",
            "Epoch 16/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.5018 - val_accuracy: 0.7628 - val_loss: 0.5209\n",
            "Epoch 17/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7686 - loss: 0.5013 - val_accuracy: 0.7616 - val_loss: 0.5208\n",
            "Epoch 18/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7684 - loss: 0.5008 - val_accuracy: 0.7634 - val_loss: 0.5206\n",
            "Epoch 19/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7689 - loss: 0.5003 - val_accuracy: 0.7634 - val_loss: 0.5205\n",
            "Epoch 20/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.7690 - loss: 0.4998 - val_accuracy: 0.7622 - val_loss: 0.5203\n",
            "Epoch 21/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7692 - loss: 0.4993 - val_accuracy: 0.7603 - val_loss: 0.5202\n",
            "Epoch 22/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7679 - loss: 0.4989 - val_accuracy: 0.7591 - val_loss: 0.5200\n",
            "Epoch 23/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7684 - loss: 0.4985 - val_accuracy: 0.7603 - val_loss: 0.5200\n",
            "Epoch 24/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7691 - loss: 0.4981 - val_accuracy: 0.7597 - val_loss: 0.5198\n",
            "Epoch 25/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7688 - loss: 0.4977 - val_accuracy: 0.7609 - val_loss: 0.5198\n",
            "Epoch 26/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7687 - loss: 0.4974 - val_accuracy: 0.7609 - val_loss: 0.5198\n",
            "Epoch 27/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.7678 - loss: 0.4970 - val_accuracy: 0.7622 - val_loss: 0.5197\n",
            "Epoch 28/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7688 - loss: 0.4967 - val_accuracy: 0.7628 - val_loss: 0.5197\n",
            "Epoch 29/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7689 - loss: 0.4963 - val_accuracy: 0.7634 - val_loss: 0.5195\n",
            "Epoch 30/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7694 - loss: 0.4960 - val_accuracy: 0.7634 - val_loss: 0.5195\n",
            "Epoch 31/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.7699 - loss: 0.4958 - val_accuracy: 0.7640 - val_loss: 0.5195\n",
            "Epoch 32/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.7700 - loss: 0.4955 - val_accuracy: 0.7634 - val_loss: 0.5195\n",
            "Epoch 33/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7695 - loss: 0.4952 - val_accuracy: 0.7634 - val_loss: 0.5195\n",
            "Epoch 34/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7702 - loss: 0.4949 - val_accuracy: 0.7634 - val_loss: 0.5195\n",
            "Epoch 35/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7701 - loss: 0.4947 - val_accuracy: 0.7646 - val_loss: 0.5194\n",
            "Epoch 36/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7698 - loss: 0.4944 - val_accuracy: 0.7640 - val_loss: 0.5195\n",
            "Epoch 37/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7704 - loss: 0.4941 - val_accuracy: 0.7652 - val_loss: 0.5195\n",
            "Epoch 38/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7715 - loss: 0.4938 - val_accuracy: 0.7652 - val_loss: 0.5195\n",
            "Epoch 39/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.7717 - loss: 0.4936 - val_accuracy: 0.7652 - val_loss: 0.5195\n",
            "Epoch 40/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7724 - loss: 0.4934 - val_accuracy: 0.7640 - val_loss: 0.5196\n",
            "Epoch 41/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7722 - loss: 0.4932 - val_accuracy: 0.7646 - val_loss: 0.5198\n",
            "Epoch 42/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7724 - loss: 0.4930 - val_accuracy: 0.7640 - val_loss: 0.5197\n",
            "Epoch 43/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7722 - loss: 0.4927 - val_accuracy: 0.7634 - val_loss: 0.5198\n",
            "Epoch 44/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7723 - loss: 0.4925 - val_accuracy: 0.7640 - val_loss: 0.5198\n",
            "Epoch 45/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.7723 - loss: 0.4923 - val_accuracy: 0.7634 - val_loss: 0.5198\n",
            "Epoch 46/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7724 - loss: 0.4920 - val_accuracy: 0.7640 - val_loss: 0.5198\n",
            "Epoch 47/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7725 - loss: 0.4918 - val_accuracy: 0.7634 - val_loss: 0.5198\n",
            "Epoch 48/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.7722 - loss: 0.4915 - val_accuracy: 0.7640 - val_loss: 0.5198\n",
            "Epoch 49/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7737 - loss: 0.4913 - val_accuracy: 0.7646 - val_loss: 0.5198\n",
            "Epoch 50/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.7749 - loss: 0.4910 - val_accuracy: 0.7634 - val_loss: 0.5199\n",
            "✅ Model Successfully Trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2️⃣ Deeper MLP with Dropout**"
      ],
      "metadata": {
        "id": "xa-wkDefIJ4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_deep = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_deep.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_deep = model_deep.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzCGYp8gIQHL",
        "outputId": "e1daa542-e17f-4e24-b9bb-a70f7d75742a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7260 - loss: 0.5689 - val_accuracy: 0.7433 - val_loss: 0.5329\n",
            "Epoch 2/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7474 - loss: 0.5335 - val_accuracy: 0.7512 - val_loss: 0.5278\n",
            "Epoch 3/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7519 - loss: 0.5302 - val_accuracy: 0.7573 - val_loss: 0.5268\n",
            "Epoch 4/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 0.7543 - loss: 0.5239 - val_accuracy: 0.7585 - val_loss: 0.5250\n",
            "Epoch 5/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7561 - loss: 0.5222 - val_accuracy: 0.7567 - val_loss: 0.5257\n",
            "Epoch 6/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.7619 - loss: 0.5182 - val_accuracy: 0.7567 - val_loss: 0.5229\n",
            "Epoch 7/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7614 - loss: 0.5181 - val_accuracy: 0.7555 - val_loss: 0.5229\n",
            "Epoch 8/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7645 - loss: 0.5172 - val_accuracy: 0.7579 - val_loss: 0.5227\n",
            "Epoch 9/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7609 - loss: 0.5162 - val_accuracy: 0.7573 - val_loss: 0.5231\n",
            "Epoch 10/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7669 - loss: 0.5096 - val_accuracy: 0.7597 - val_loss: 0.5217\n",
            "Epoch 11/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7672 - loss: 0.5128 - val_accuracy: 0.7646 - val_loss: 0.5207\n",
            "Epoch 12/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7612 - loss: 0.5132 - val_accuracy: 0.7646 - val_loss: 0.5202\n",
            "Epoch 13/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7610 - loss: 0.5147 - val_accuracy: 0.7603 - val_loss: 0.5215\n",
            "Epoch 14/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7660 - loss: 0.5128 - val_accuracy: 0.7603 - val_loss: 0.5198\n",
            "Epoch 15/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7665 - loss: 0.5091 - val_accuracy: 0.7603 - val_loss: 0.5194\n",
            "Epoch 16/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7633 - loss: 0.5099 - val_accuracy: 0.7622 - val_loss: 0.5195\n",
            "Epoch 17/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7673 - loss: 0.5117 - val_accuracy: 0.7640 - val_loss: 0.5197\n",
            "Epoch 18/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7629 - loss: 0.5117 - val_accuracy: 0.7640 - val_loss: 0.5188\n",
            "Epoch 19/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.7676 - loss: 0.5107 - val_accuracy: 0.7603 - val_loss: 0.5194\n",
            "Epoch 20/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.7718 - loss: 0.5069 - val_accuracy: 0.7628 - val_loss: 0.5180\n",
            "Epoch 21/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7658 - loss: 0.5043 - val_accuracy: 0.7646 - val_loss: 0.5171\n",
            "Epoch 22/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7709 - loss: 0.5043 - val_accuracy: 0.7616 - val_loss: 0.5173\n",
            "Epoch 23/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7627 - loss: 0.5082 - val_accuracy: 0.7603 - val_loss: 0.5177\n",
            "Epoch 24/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7663 - loss: 0.5062 - val_accuracy: 0.7603 - val_loss: 0.5181\n",
            "Epoch 25/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.7690 - loss: 0.5021 - val_accuracy: 0.7646 - val_loss: 0.5180\n",
            "Epoch 26/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7666 - loss: 0.5064 - val_accuracy: 0.7634 - val_loss: 0.5187\n",
            "Epoch 27/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7683 - loss: 0.5028 - val_accuracy: 0.7634 - val_loss: 0.5183\n",
            "Epoch 28/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7695 - loss: 0.5021 - val_accuracy: 0.7622 - val_loss: 0.5178\n",
            "Epoch 29/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7650 - loss: 0.5057 - val_accuracy: 0.7616 - val_loss: 0.5181\n",
            "Epoch 30/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7683 - loss: 0.5045 - val_accuracy: 0.7646 - val_loss: 0.5174\n",
            "Epoch 31/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7713 - loss: 0.4978 - val_accuracy: 0.7579 - val_loss: 0.5177\n",
            "Epoch 32/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7697 - loss: 0.5014 - val_accuracy: 0.7567 - val_loss: 0.5174\n",
            "Epoch 33/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7676 - loss: 0.5014 - val_accuracy: 0.7591 - val_loss: 0.5161\n",
            "Epoch 34/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7700 - loss: 0.4997 - val_accuracy: 0.7609 - val_loss: 0.5169\n",
            "Epoch 35/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7760 - loss: 0.4976 - val_accuracy: 0.7628 - val_loss: 0.5153\n",
            "Epoch 36/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.7744 - loss: 0.4958 - val_accuracy: 0.7591 - val_loss: 0.5166\n",
            "Epoch 37/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7712 - loss: 0.4965 - val_accuracy: 0.7597 - val_loss: 0.5163\n",
            "Epoch 38/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7685 - loss: 0.4998 - val_accuracy: 0.7591 - val_loss: 0.5167\n",
            "Epoch 39/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7748 - loss: 0.4969 - val_accuracy: 0.7561 - val_loss: 0.5175\n",
            "Epoch 40/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.7679 - loss: 0.4971 - val_accuracy: 0.7609 - val_loss: 0.5165\n",
            "Epoch 41/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7733 - loss: 0.4982 - val_accuracy: 0.7573 - val_loss: 0.5164\n",
            "Epoch 42/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7653 - loss: 0.4975 - val_accuracy: 0.7573 - val_loss: 0.5158\n",
            "Epoch 43/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7780 - loss: 0.4964 - val_accuracy: 0.7591 - val_loss: 0.5167\n",
            "Epoch 44/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7706 - loss: 0.4934 - val_accuracy: 0.7561 - val_loss: 0.5169\n",
            "Epoch 45/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7815 - loss: 0.4962 - val_accuracy: 0.7603 - val_loss: 0.5164\n",
            "Epoch 46/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7773 - loss: 0.4937 - val_accuracy: 0.7591 - val_loss: 0.5155\n",
            "Epoch 47/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.7759 - loss: 0.4926 - val_accuracy: 0.7579 - val_loss: 0.5150\n",
            "Epoch 48/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7722 - loss: 0.4907 - val_accuracy: 0.7622 - val_loss: 0.5158\n",
            "Epoch 49/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7764 - loss: 0.4917 - val_accuracy: 0.7603 - val_loss: 0.5160\n",
            "Epoch 50/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7837 - loss: 0.4865 - val_accuracy: 0.7622 - val_loss: 0.5162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3️⃣ Wide MLP (More Neurons per Layer)**"
      ],
      "metadata": {
        "id": "EEBX_lKaNoG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_wide = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.4),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_wide.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_wide = model_wide.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDVzPWsgNocb",
        "outputId": "d1068db2-e9e6-4d29-c058-9c798f00c093"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7151 - loss: 0.5663 - val_accuracy: 0.7579 - val_loss: 0.5278\n",
            "Epoch 2/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7593 - loss: 0.5243 - val_accuracy: 0.7567 - val_loss: 0.5265\n",
            "Epoch 3/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7560 - loss: 0.5223 - val_accuracy: 0.7622 - val_loss: 0.5240\n",
            "Epoch 4/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7542 - loss: 0.5208 - val_accuracy: 0.7622 - val_loss: 0.5226\n",
            "Epoch 5/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7625 - loss: 0.5159 - val_accuracy: 0.7628 - val_loss: 0.5228\n",
            "Epoch 6/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7613 - loss: 0.5155 - val_accuracy: 0.7628 - val_loss: 0.5208\n",
            "Epoch 7/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.7640 - loss: 0.5159 - val_accuracy: 0.7622 - val_loss: 0.5212\n",
            "Epoch 8/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7613 - loss: 0.5139 - val_accuracy: 0.7622 - val_loss: 0.5214\n",
            "Epoch 9/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7608 - loss: 0.5096 - val_accuracy: 0.7640 - val_loss: 0.5198\n",
            "Epoch 10/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7592 - loss: 0.5131 - val_accuracy: 0.7622 - val_loss: 0.5201\n",
            "Epoch 11/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7606 - loss: 0.5144 - val_accuracy: 0.7597 - val_loss: 0.5192\n",
            "Epoch 12/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7670 - loss: 0.5060 - val_accuracy: 0.7622 - val_loss: 0.5188\n",
            "Epoch 13/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.7671 - loss: 0.5048 - val_accuracy: 0.7585 - val_loss: 0.5193\n",
            "Epoch 14/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.5107 - val_accuracy: 0.7646 - val_loss: 0.5184\n",
            "Epoch 15/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7634 - loss: 0.5057 - val_accuracy: 0.7628 - val_loss: 0.5177\n",
            "Epoch 16/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7720 - loss: 0.5047 - val_accuracy: 0.7603 - val_loss: 0.5187\n",
            "Epoch 17/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7685 - loss: 0.5006 - val_accuracy: 0.7622 - val_loss: 0.5178\n",
            "Epoch 18/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7674 - loss: 0.5026 - val_accuracy: 0.7634 - val_loss: 0.5172\n",
            "Epoch 19/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7695 - loss: 0.5021 - val_accuracy: 0.7591 - val_loss: 0.5188\n",
            "Epoch 20/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7693 - loss: 0.5003 - val_accuracy: 0.7591 - val_loss: 0.5179\n",
            "Epoch 21/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.7698 - loss: 0.4975 - val_accuracy: 0.7597 - val_loss: 0.5184\n",
            "Epoch 22/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7658 - loss: 0.4994 - val_accuracy: 0.7616 - val_loss: 0.5169\n",
            "Epoch 23/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7639 - loss: 0.5009 - val_accuracy: 0.7603 - val_loss: 0.5159\n",
            "Epoch 24/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7724 - loss: 0.4946 - val_accuracy: 0.7573 - val_loss: 0.5181\n",
            "Epoch 25/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7740 - loss: 0.4985 - val_accuracy: 0.7603 - val_loss: 0.5166\n",
            "Epoch 26/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7753 - loss: 0.4945 - val_accuracy: 0.7567 - val_loss: 0.5167\n",
            "Epoch 27/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7754 - loss: 0.4953 - val_accuracy: 0.7591 - val_loss: 0.5166\n",
            "Epoch 28/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7689 - loss: 0.4921 - val_accuracy: 0.7603 - val_loss: 0.5177\n",
            "Epoch 29/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7773 - loss: 0.4917 - val_accuracy: 0.7585 - val_loss: 0.5178\n",
            "Epoch 30/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.4931 - val_accuracy: 0.7597 - val_loss: 0.5168\n",
            "Epoch 31/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7733 - loss: 0.4906 - val_accuracy: 0.7591 - val_loss: 0.5174\n",
            "Epoch 32/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7718 - loss: 0.4927 - val_accuracy: 0.7591 - val_loss: 0.5157\n",
            "Epoch 33/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7690 - loss: 0.4918 - val_accuracy: 0.7549 - val_loss: 0.5172\n",
            "Epoch 34/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.7757 - loss: 0.4873 - val_accuracy: 0.7597 - val_loss: 0.5161\n",
            "Epoch 35/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7676 - loss: 0.4887 - val_accuracy: 0.7603 - val_loss: 0.5153\n",
            "Epoch 36/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7824 - loss: 0.4834 - val_accuracy: 0.7561 - val_loss: 0.5176\n",
            "Epoch 37/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7802 - loss: 0.4851 - val_accuracy: 0.7616 - val_loss: 0.5177\n",
            "Epoch 38/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.7800 - loss: 0.4880 - val_accuracy: 0.7591 - val_loss: 0.5191\n",
            "Epoch 39/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.7765 - loss: 0.4842 - val_accuracy: 0.7597 - val_loss: 0.5174\n",
            "Epoch 40/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7766 - loss: 0.4862 - val_accuracy: 0.7561 - val_loss: 0.5195\n",
            "Epoch 41/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.4816 - val_accuracy: 0.7603 - val_loss: 0.5203\n",
            "Epoch 42/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7852 - loss: 0.4782 - val_accuracy: 0.7585 - val_loss: 0.5209\n",
            "Epoch 43/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7775 - loss: 0.4793 - val_accuracy: 0.7585 - val_loss: 0.5200\n",
            "Epoch 44/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7821 - loss: 0.4824 - val_accuracy: 0.7536 - val_loss: 0.5207\n",
            "Epoch 45/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7791 - loss: 0.4807 - val_accuracy: 0.7634 - val_loss: 0.5186\n",
            "Epoch 46/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7827 - loss: 0.4755 - val_accuracy: 0.7591 - val_loss: 0.5208\n",
            "Epoch 47/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7793 - loss: 0.4769 - val_accuracy: 0.7616 - val_loss: 0.5216\n",
            "Epoch 48/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.7775 - loss: 0.4789 - val_accuracy: 0.7609 - val_loss: 0.5203\n",
            "Epoch 49/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7777 - loss: 0.4781 - val_accuracy: 0.7622 - val_loss: 0.5221\n",
            "Epoch 50/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7821 - loss: 0.4785 - val_accuracy: 0.7591 - val_loss: 0.5220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4️⃣ L1 & L2 Regularization (Prevents Overfitting)**"
      ],
      "metadata": {
        "id": "JXEH-WzTN4mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l1_l2\n",
        "\n",
        "model_regularized = Sequential([\n",
        "    Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001), input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.001, l2=0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_regularized.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_regularized = model_regularized.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me5CP2PQN7al",
        "outputId": "eeeac3fd-89f4-49ce-a56d-b88f1d240b10"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7122 - loss: 1.3942 - val_accuracy: 0.7464 - val_loss: 0.9351\n",
            "Epoch 2/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7503 - loss: 0.8659 - val_accuracy: 0.7476 - val_loss: 0.7093\n",
            "Epoch 3/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7463 - loss: 0.6783 - val_accuracy: 0.7451 - val_loss: 0.6207\n",
            "Epoch 4/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7443 - loss: 0.6077 - val_accuracy: 0.7457 - val_loss: 0.5869\n",
            "Epoch 5/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7408 - loss: 0.5801 - val_accuracy: 0.7482 - val_loss: 0.5711\n",
            "Epoch 6/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.5682 - val_accuracy: 0.7488 - val_loss: 0.5623\n",
            "Epoch 7/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7449 - loss: 0.5595 - val_accuracy: 0.7524 - val_loss: 0.5577\n",
            "Epoch 8/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7456 - loss: 0.5580 - val_accuracy: 0.7488 - val_loss: 0.5549\n",
            "Epoch 9/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7471 - loss: 0.5532 - val_accuracy: 0.7506 - val_loss: 0.5529\n",
            "Epoch 10/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7483 - loss: 0.5535 - val_accuracy: 0.7543 - val_loss: 0.5520\n",
            "Epoch 11/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7419 - loss: 0.5531 - val_accuracy: 0.7488 - val_loss: 0.5518\n",
            "Epoch 12/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7479 - loss: 0.5525 - val_accuracy: 0.7530 - val_loss: 0.5506\n",
            "Epoch 13/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.7487 - loss: 0.5501 - val_accuracy: 0.7549 - val_loss: 0.5497\n",
            "Epoch 14/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7479 - loss: 0.5476 - val_accuracy: 0.7506 - val_loss: 0.5493\n",
            "Epoch 15/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7440 - loss: 0.5499 - val_accuracy: 0.7512 - val_loss: 0.5490\n",
            "Epoch 16/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.7497 - loss: 0.5501 - val_accuracy: 0.7555 - val_loss: 0.5484\n",
            "Epoch 17/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7472 - loss: 0.5490 - val_accuracy: 0.7512 - val_loss: 0.5479\n",
            "Epoch 18/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.7424 - loss: 0.5505 - val_accuracy: 0.7518 - val_loss: 0.5487\n",
            "Epoch 19/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7440 - loss: 0.5481 - val_accuracy: 0.7567 - val_loss: 0.5474\n",
            "Epoch 20/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7515 - loss: 0.5478 - val_accuracy: 0.7494 - val_loss: 0.5480\n",
            "Epoch 21/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.7455 - loss: 0.5456 - val_accuracy: 0.7506 - val_loss: 0.5466\n",
            "Epoch 22/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7437 - loss: 0.5471 - val_accuracy: 0.7494 - val_loss: 0.5468\n",
            "Epoch 23/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7514 - loss: 0.5473 - val_accuracy: 0.7488 - val_loss: 0.5463\n",
            "Epoch 24/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7445 - loss: 0.5471 - val_accuracy: 0.7506 - val_loss: 0.5470\n",
            "Epoch 25/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7461 - loss: 0.5485 - val_accuracy: 0.7536 - val_loss: 0.5474\n",
            "Epoch 26/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.7463 - loss: 0.5473 - val_accuracy: 0.7518 - val_loss: 0.5463\n",
            "Epoch 27/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.7456 - loss: 0.5445 - val_accuracy: 0.7555 - val_loss: 0.5459\n",
            "Epoch 28/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7453 - loss: 0.5457 - val_accuracy: 0.7500 - val_loss: 0.5456\n",
            "Epoch 29/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7445 - loss: 0.5479 - val_accuracy: 0.7500 - val_loss: 0.5459\n",
            "Epoch 30/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7468 - loss: 0.5497 - val_accuracy: 0.7518 - val_loss: 0.5459\n",
            "Epoch 31/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7461 - loss: 0.5440 - val_accuracy: 0.7500 - val_loss: 0.5453\n",
            "Epoch 32/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7420 - loss: 0.5496 - val_accuracy: 0.7500 - val_loss: 0.5455\n",
            "Epoch 33/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7419 - loss: 0.5427 - val_accuracy: 0.7512 - val_loss: 0.5457\n",
            "Epoch 34/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.7435 - loss: 0.5452 - val_accuracy: 0.7543 - val_loss: 0.5475\n",
            "Epoch 35/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7446 - loss: 0.5448 - val_accuracy: 0.7543 - val_loss: 0.5461\n",
            "Epoch 36/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7493 - loss: 0.5479 - val_accuracy: 0.7506 - val_loss: 0.5451\n",
            "Epoch 37/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7505 - loss: 0.5427 - val_accuracy: 0.7567 - val_loss: 0.5456\n",
            "Epoch 38/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7513 - loss: 0.5414 - val_accuracy: 0.7543 - val_loss: 0.5456\n",
            "Epoch 39/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7448 - loss: 0.5483 - val_accuracy: 0.7506 - val_loss: 0.5457\n",
            "Epoch 40/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7440 - loss: 0.5436 - val_accuracy: 0.7555 - val_loss: 0.5446\n",
            "Epoch 41/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.5488 - val_accuracy: 0.7536 - val_loss: 0.5452\n",
            "Epoch 42/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7429 - loss: 0.5426 - val_accuracy: 0.7500 - val_loss: 0.5445\n",
            "Epoch 43/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7454 - loss: 0.5479 - val_accuracy: 0.7543 - val_loss: 0.5441\n",
            "Epoch 44/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7481 - loss: 0.5425 - val_accuracy: 0.7500 - val_loss: 0.5450\n",
            "Epoch 45/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7446 - loss: 0.5451 - val_accuracy: 0.7500 - val_loss: 0.5438\n",
            "Epoch 46/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7463 - loss: 0.5425 - val_accuracy: 0.7488 - val_loss: 0.5450\n",
            "Epoch 47/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.7454 - loss: 0.5420 - val_accuracy: 0.7549 - val_loss: 0.5451\n",
            "Epoch 48/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7534 - loss: 0.5438 - val_accuracy: 0.7549 - val_loss: 0.5449\n",
            "Epoch 49/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7481 - loss: 0.5447 - val_accuracy: 0.7579 - val_loss: 0.5442\n",
            "Epoch 50/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7486 - loss: 0.5423 - val_accuracy: 0.7530 - val_loss: 0.5441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5️⃣ Optimized Learning Rate with Adam**"
      ],
      "metadata": {
        "id": "TsntgCm0N61e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_tuned_lr = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_tuned_lr.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_tuned_lr = model_tuned_lr.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X9t3-ScN-QN",
        "outputId": "46fcdbfc-844a-46a2-cbc6-aea1abc42e80"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7207 - loss: 0.5858 - val_accuracy: 0.7470 - val_loss: 0.5373\n",
            "Epoch 2/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7456 - loss: 0.5440 - val_accuracy: 0.7482 - val_loss: 0.5326\n",
            "Epoch 3/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7455 - loss: 0.5381 - val_accuracy: 0.7518 - val_loss: 0.5311\n",
            "Epoch 4/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.5310 - val_accuracy: 0.7512 - val_loss: 0.5284\n",
            "Epoch 5/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.7503 - loss: 0.5247 - val_accuracy: 0.7500 - val_loss: 0.5268\n",
            "Epoch 6/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7492 - loss: 0.5254 - val_accuracy: 0.7530 - val_loss: 0.5251\n",
            "Epoch 7/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.7558 - loss: 0.5208 - val_accuracy: 0.7567 - val_loss: 0.5249\n",
            "Epoch 8/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7598 - loss: 0.5200 - val_accuracy: 0.7567 - val_loss: 0.5245\n",
            "Epoch 9/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.7536 - loss: 0.5189 - val_accuracy: 0.7603 - val_loss: 0.5245\n",
            "Epoch 10/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7571 - loss: 0.5207 - val_accuracy: 0.7616 - val_loss: 0.5241\n",
            "Epoch 11/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7555 - loss: 0.5225 - val_accuracy: 0.7634 - val_loss: 0.5232\n",
            "Epoch 12/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.7595 - loss: 0.5196 - val_accuracy: 0.7616 - val_loss: 0.5228\n",
            "Epoch 13/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.7594 - loss: 0.5170 - val_accuracy: 0.7634 - val_loss: 0.5230\n",
            "Epoch 14/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7620 - loss: 0.5116 - val_accuracy: 0.7597 - val_loss: 0.5223\n",
            "Epoch 15/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.7610 - loss: 0.5138 - val_accuracy: 0.7597 - val_loss: 0.5227\n",
            "Epoch 16/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7650 - loss: 0.5092 - val_accuracy: 0.7585 - val_loss: 0.5224\n",
            "Epoch 17/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7643 - loss: 0.5094 - val_accuracy: 0.7640 - val_loss: 0.5212\n",
            "Epoch 18/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7609 - loss: 0.5129 - val_accuracy: 0.7609 - val_loss: 0.5204\n",
            "Epoch 19/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7649 - loss: 0.5090 - val_accuracy: 0.7616 - val_loss: 0.5203\n",
            "Epoch 20/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.7662 - loss: 0.5085 - val_accuracy: 0.7616 - val_loss: 0.5198\n",
            "Epoch 21/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7609 - loss: 0.5141 - val_accuracy: 0.7591 - val_loss: 0.5209\n",
            "Epoch 22/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7631 - loss: 0.5111 - val_accuracy: 0.7603 - val_loss: 0.5205\n",
            "Epoch 23/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7633 - loss: 0.5108 - val_accuracy: 0.7634 - val_loss: 0.5196\n",
            "Epoch 24/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7618 - loss: 0.5142 - val_accuracy: 0.7622 - val_loss: 0.5195\n",
            "Epoch 25/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7638 - loss: 0.5096 - val_accuracy: 0.7658 - val_loss: 0.5190\n",
            "Epoch 26/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7650 - loss: 0.5091 - val_accuracy: 0.7609 - val_loss: 0.5189\n",
            "Epoch 27/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7632 - loss: 0.5034 - val_accuracy: 0.7616 - val_loss: 0.5189\n",
            "Epoch 28/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.7677 - loss: 0.5082 - val_accuracy: 0.7634 - val_loss: 0.5189\n",
            "Epoch 29/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7622 - loss: 0.5056 - val_accuracy: 0.7609 - val_loss: 0.5182\n",
            "Epoch 30/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7674 - loss: 0.5061 - val_accuracy: 0.7603 - val_loss: 0.5187\n",
            "Epoch 31/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.7615 - loss: 0.5039 - val_accuracy: 0.7609 - val_loss: 0.5185\n",
            "Epoch 32/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7673 - loss: 0.5051 - val_accuracy: 0.7640 - val_loss: 0.5179\n",
            "Epoch 33/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7708 - loss: 0.5038 - val_accuracy: 0.7609 - val_loss: 0.5187\n",
            "Epoch 34/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7686 - loss: 0.5055 - val_accuracy: 0.7622 - val_loss: 0.5182\n",
            "Epoch 35/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7648 - loss: 0.5041 - val_accuracy: 0.7622 - val_loss: 0.5184\n",
            "Epoch 36/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.7617 - loss: 0.5059 - val_accuracy: 0.7603 - val_loss: 0.5190\n",
            "Epoch 37/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.7647 - loss: 0.5077 - val_accuracy: 0.7652 - val_loss: 0.5172\n",
            "Epoch 38/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7690 - loss: 0.5030 - val_accuracy: 0.7634 - val_loss: 0.5166\n",
            "Epoch 39/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7709 - loss: 0.5074 - val_accuracy: 0.7628 - val_loss: 0.5172\n",
            "Epoch 40/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7704 - loss: 0.5029 - val_accuracy: 0.7622 - val_loss: 0.5166\n",
            "Epoch 41/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7713 - loss: 0.5032 - val_accuracy: 0.7628 - val_loss: 0.5167\n",
            "Epoch 42/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7696 - loss: 0.5047 - val_accuracy: 0.7640 - val_loss: 0.5165\n",
            "Epoch 43/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.7665 - loss: 0.5020 - val_accuracy: 0.7634 - val_loss: 0.5153\n",
            "Epoch 44/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.7669 - loss: 0.4995 - val_accuracy: 0.7646 - val_loss: 0.5150\n",
            "Epoch 45/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7714 - loss: 0.4993 - val_accuracy: 0.7609 - val_loss: 0.5164\n",
            "Epoch 46/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.7715 - loss: 0.4978 - val_accuracy: 0.7640 - val_loss: 0.5152\n",
            "Epoch 47/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7710 - loss: 0.5009 - val_accuracy: 0.7622 - val_loss: 0.5153\n",
            "Epoch 48/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7689 - loss: 0.5058 - val_accuracy: 0.7640 - val_loss: 0.5150\n",
            "Epoch 49/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7690 - loss: 0.4978 - val_accuracy: 0.7616 - val_loss: 0.5155\n",
            "Epoch 50/50\n",
            "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7703 - loss: 0.5006 - val_accuracy: 0.7658 - val_loss: 0.5151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparing the Models**"
      ],
      "metadata": {
        "id": "kwRZg9eFOE4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(\"Unique values in y_test:\", np.unique(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXyGmIuZb8Ob",
        "outputId": "5f25a581-3171-411d-c828-04195a8bc548"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in y_test: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_model(model, name):\n",
        "    y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
        "    print(f\"\\n✅ {name} Model Performance:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['lowDOA', 'highDOA']))\n",
        "\n",
        "# Evaluate all models\n",
        "evaluate_model(model_base, \"Base MLP\")\n",
        "evaluate_model(model_deep, \"Deep MLP\")\n",
        "evaluate_model(model_wide, \"Wide MLP\")\n",
        "evaluate_model(model_regularized, \"Regularized MLP\")\n",
        "evaluate_model(model_tuned_lr, \"Optimized Learning Rate MLP\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyhyUsNXdmRN",
        "outputId": "8f54d36e-82a4-4e24-c45c-2be0a64d94f0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
            "\n",
            "✅ Base MLP Model Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      lowDOA       0.60      0.28      0.38       431\n",
            "     highDOA       0.79      0.93      0.85      1213\n",
            "\n",
            "    accuracy                           0.76      1644\n",
            "   macro avg       0.70      0.61      0.62      1644\n",
            "weighted avg       0.74      0.76      0.73      1644\n",
            "\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "✅ Deep MLP Model Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      lowDOA       0.62      0.24      0.34       431\n",
            "     highDOA       0.78      0.95      0.85      1213\n",
            "\n",
            "    accuracy                           0.76      1644\n",
            "   macro avg       0.70      0.59      0.60      1644\n",
            "weighted avg       0.74      0.76      0.72      1644\n",
            "\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "✅ Wide MLP Model Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      lowDOA       0.61      0.22      0.32       431\n",
            "     highDOA       0.77      0.95      0.85      1213\n",
            "\n",
            "    accuracy                           0.76      1644\n",
            "   macro avg       0.69      0.59      0.59      1644\n",
            "weighted avg       0.73      0.76      0.71      1644\n",
            "\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
            "\n",
            "✅ Regularized MLP Model Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      lowDOA       0.63      0.14      0.23       431\n",
            "     highDOA       0.76      0.97      0.85      1213\n",
            "\n",
            "    accuracy                           0.75      1644\n",
            "   macro avg       0.70      0.56      0.54      1644\n",
            "weighted avg       0.73      0.75      0.69      1644\n",
            "\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\n",
            "✅ Optimized Learning Rate MLP Model Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      lowDOA       0.63      0.26      0.36       431\n",
            "     highDOA       0.78      0.95      0.86      1213\n",
            "\n",
            "    accuracy                           0.77      1644\n",
            "   macro avg       0.71      0.60      0.61      1644\n",
            "weighted avg       0.74      0.77      0.73      1644\n",
            "\n"
          ]
        }
      ]
    }
  ]
}